\doxysection{Référence de l\textquotesingle{}espace de nommage charset\+\_\+normalizer}
\hypertarget{namespacecharset__normalizer}{}\label{namespacecharset__normalizer}\index{charset\_normalizer@{charset\_normalizer}}
\doxysubsubsection*{Espaces de nommage}
\begin{DoxyCompactItemize}
\item 
namespace \mbox{\hyperlink{namespacecharset__normalizer_1_1version}{version}}
\end{DoxyCompactItemize}


\doxysubsection{Description détaillée}
\begin{DoxyVerb}Charset-Normalizer
~~~~~~~~~~~~~~
The Real First Universal Charset Detector.
A library that helps you read text from an unknown charset encoding.
Motivated by chardet, This package is trying to resolve the issue by taking a new approach.
All IANA character set names for which the Python core library provides codecs are supported.

Basic usage:
   >>> from charset_normalizer import from_bytes
   >>> results = from_bytes('Bсеки човек има право на образование. Oбразованието!'.encode('utf_8'))
   >>> best_guess = results.best()
   >>> str(best_guess)
   'Bсеки човек има право на образование. Oбразованието!'

Others methods and usages are available - see the full documentation
at <https://github.com/Ousret/charset_normalizer>.
:copyright: (c) 2021 by Ahmed TAHRI
:license: MIT, see LICENSE for more details.
\end{DoxyVerb}
 